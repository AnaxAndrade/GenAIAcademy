# Explorar ferramentas e plataformas que apoiam o deploy em produção
O objetivo é conhecer algumas das principais ferramentas que temos para apoiar no deploy em produção das nossas soluções de AI.

## Open Web UI
Uma plataforma de interface de usuário para interagir com modelos de inteligência artificial.

[Open Web UI Docs - AI UI Platform](https://docs.openwebui.com/)

## Python Flask
Um microframework em Python para criar aplicações web rápidas e simples.

[Flask Documentation](https://flask.palletsprojects.com/en/stable/)

## Containers
Tecnologia para empacotar aplicações e suas dependências em ambientes isolados.

[Docker Documentation](https://www.docker.com/)

## HuggingFace Inference Endpoints
Serviço para hospedar e servir modelos de machine learning em produção.

[HuggingFace Inference Endpoints Documentation](https://huggingface.co/docs/inference-endpoints/index)

## NVIDIA NIM & Triton Server (Dynamo)
Soluções de inferência de IA otimizadas para alto desempenho e escalabilidade.

[NVIDIA Inference Solution](https://developer.nvidia.com/topics/ai/ai-inference?sortBy=developer_learning_library%2Fsort%2Ffeatured_in.inference%3Adesc%2Ctitle%3Aasc)

## Azure OpenAI services
Serviços na nuvem para integrar modelos de OpenAI em soluções empresariais.

[Criação de recursos no Azure OpenAI](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal)
