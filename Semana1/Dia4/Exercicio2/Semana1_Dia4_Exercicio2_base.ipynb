{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercício: Sentimento em Tweets Portugueses com GRU (PyTorch)\n",
        "* **Descrição:** Classificar tweets PT em positivo/negativo usando GRU bidireccional.\n",
        "* **Dataset:** Portuguese Tweets for Sentiment Analysis (10 k tweets)\n",
        "  * **Mais Informações:** https://www.kaggle.com/datasets/augustop/portuguese-tweets-for-sentiment-analysis?utm_source=chatgpt.com"
      ],
      "metadata": {
        "id": "Faebs66OYZ3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo a passo\n",
        "\n",
        "1. Carregar tweet, sentiment; mapear posit→1, neg→0.\n",
        "2. Tokenizar com torchtext SpaCyTokenizer('pt'), cortar a 50 tokens.\n",
        "3. Embedding(num_embeddings=20 000, dim=128) + Bidirectional GRU(128).\n",
        "4. Otimizador Adam, BCELoss; epochs = 10, batch = 64 (GPU).\n",
        "5. Medir accuracy & F1 no conjunto de teste; imprimir frases mal-classificadas.\n",
        "\n"
      ],
      "metadata": {
        "id": "FoH8E5--ZOf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Opção de download do dataset\n",
        "\n",
        "# Treino (Train50.csv são 50 mil tweets)\n",
        "# Pode usar também Train100.csv, Train200.csv, Train300.csv, Train400.csv, Train500.csv)\n",
        "!wget https://genaiacademy.s3.eu-west-3.amazonaws.com/tweetspt/TrainingDatasets/Train50.csv\n",
        "\n",
        "# Teste\n",
        "!wget https://genaiacademy.s3.eu-west-3.amazonaws.com/tweetspt/TestDatasets/Test.csv\n"
      ],
      "metadata": {
        "id": "miGoUMBJm5o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch torchtext spacy==3.7.2 pt_core_news_sm\n",
        "import torch, torch.nn as nn, torchtext\n",
        "import pandas as pd, spacy, random, numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "nDYhAUP2aFA7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}