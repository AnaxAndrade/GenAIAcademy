{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMeJf4cLM3R_"
      },
      "source": [
        "# Exerc√≠cio: An√°lise de Sentimento de Avalia√ß√µes de Clientes\n",
        "* **Descri√ß√£o:** Classificar reviews Olist em positivas/negativas para medir satisfa√ß√£o.\n",
        "Dataset: Brazilian E-Commerce Public Dataset (Kaggle) ‚Äî tabela olist_order_reviews_dataset.csv\n",
        "* **Dataset:** Dataset p√∫blico de e-commerce publicado pela empresa __olist.com__\n",
        "  * **Download:** https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQGkCFovNzop"
      },
      "source": [
        "## Passo a passo\n",
        "\n",
        "1. Ler CSV; criar r√≥tulo: positiva se review_score‚â•4, negativa se ‚â§2.\n",
        "2. Separar treino/teste 80 / 20.\n",
        "3. TfidfVectorizer(max_features=10 000, ngram_range=(1,2)) sobre review_comment_message.\n",
        "4. Treinar LogisticRegression(max_iter=1000).\n",
        "5. Avaliar precis√£o, recall, F1; inspecionar 5 erros mais graves.\n",
        "6. Gerar nuvem de palavras por classe para insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrmQcQcWQdSE"
      },
      "source": [
        "## Download do Dataset\n",
        "\n",
        "\n",
        "*   Do AWS: https://genaiacademy.s3.eu-west-3.amazonaws.com/datasets/olist/olist_order_reviews_dataset.csv\n",
        "*   Do Kaggle: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce\n",
        "* Arquivo: olist_order_reviews_dataset.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kki6OEfDSAEd"
      },
      "outputs": [],
      "source": [
        "# Opcional: Se quizer fazer o download do arquivo direto do meu Google Drive\n",
        "\n",
        "# NOTA: Em ambiente do Google colab o gdown j√° funciona diretamente\n",
        "# caso necess√°rio pode instal√°-lo via pip, descomentanto a linha abaixo:\n",
        "# !pip install gdown\n",
        "\n",
        "!wget  https://genaiacademy.s3.eu-west-3.amazonaws.com/datasets/olist/olist_order_reviews_dataset.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUoPaB6sO3-c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v385E6HtO4Mn"
      },
      "outputs": [],
      "source": [
        "# 1. Carregar dados\n",
        "df = pd.read_csv('olist_order_reviews_dataset.csv')\n",
        "df = df[df['review_score'].isin([1,2,4,5])].dropna(subset=['review_comment_message'])\n",
        "\n",
        "# 2. Definir labels\n",
        "df['label'] = (df['review_score']>=4).astype(int)  # 1=positivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ACzkyiuO4pO"
      },
      "outputs": [],
      "source": [
        "# 3. Fazer o split entre dados de treinamento e os de teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['review_comment_message'], df['label'], test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0imtEDOPMzr"
      },
      "outputs": [],
      "source": [
        "# (Opcional) - An√°lise explorat√≥ria de dados, mostrando\n",
        "# nuvem de palavras positivas\n",
        "wc = WordCloud(width=600, height=400).generate(' '.join(X_train[y_train==1]))\n",
        "plt.imshow(wc); plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUkpOa5qTMwh"
      },
      "outputs": [],
      "source": [
        "# nuvem de palavras negativas\n",
        "wc2 = WordCloud(width=600, height=400).generate(' '.join(X_train[y_train!=1]))\n",
        "plt.imshow(wc2); plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4ChNcljSKvS"
      },
      "outputs": [],
      "source": [
        "# 4. Vectorizar\n",
        "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1,2), stop_words=None)\n",
        "Xtr = tfidf.fit_transform(X_train)\n",
        "Xte = tfidf.transform(X_test)\n",
        "\n",
        "# 5. Treinar\n",
        "clf = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
        "clf.fit(Xtr, y_train)\n",
        "print(classification_report(y_test, clf.predict(Xte)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIYay7lBWZaX"
      },
      "source": [
        "## Testar manualmente o modelo treinado\n",
        "* J√° temos um classificador pronto\n",
        "* Agora seria interessante aproveitar o modelo e test√°-lo com frases arbitr√°rias fornecidas por n√≥s\n",
        "* **Ex: Entradas teste manual**\n",
        "  * nunca mais compro\n",
        "  * muito obrigado\n",
        "  * n√£o recebi o produto\n",
        "  * voc√™s s√£o p√©ssimos\n",
        "  * gostei demais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zHnGvNWSnJ8"
      },
      "outputs": [],
      "source": [
        "# 6. [Extra] Usar o modelo treinado para prever frases de input pelo user\n",
        "user_review = input(\"Qual o seu feedback da compra?: \")\n",
        "sentimmetos = [\"Negativo üö´\", \"Positivo ‚úÖ\"]\n",
        "previsto = clf.predict(tfidf.transform([user_review]))\n",
        "print(\"Sentimento previsto:\", sentimmetos[previsto[0]])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
