{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Download do Dataset\n",
        "* Para facilitar, fiz o upload do arquivo .csv no Google drive, link: https://drive.google.com/file/d/1FiIb0dliKf18NsbSCZmz27xXy0MXV8Iq/view\n",
        "* Para fazer download é só executar o comando mais abaixo\n",
        "* Caso o link ou o comando abaixo não funcionem, tem de fazer o download direto do próprio kaggle"
      ],
      "metadata": {
        "id": "rgGl2wm69x0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Opcional: Se quizer fazer o download do arquivo direto do meu Google Drive\n",
        "\n",
        "# NOTA: Em ambiente do Google colab o gdown já funciona diretamente\n",
        "# caso necessário pode instalá-lo via pip, descomentanto a linha abaixo:\n",
        "# !pip install gdown\n",
        "\n",
        "!gdown 1FiIb0dliKf18NsbSCZmz27xXy0MXV8Iq -O emails.csv"
      ],
      "metadata": {
        "id": "gQtjRBYS-Nj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependências\n",
        "#!pip install pandas scikit-learn spacy==3.7.2 spacy-lookups-data pyLDAvis\n",
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "id": "utyg_sf15yFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, re, spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "metadata": {
        "id": "ouH9xetb53Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. carregar\n",
        "# NOTA: O dataset completo inclui mais de 500 mil emails\n",
        "# Para uma análise inicial pode ser interessante carregar uma amostra menor\n",
        "# por questões de tempo e performance\n",
        "amostra = 20000\n",
        "\n",
        "df = pd.read_csv('emails.csv')\n",
        "df = df[df['file'].str.contains('sent|inbox', na=False)].sample(amostra, random_state=42)"
      ],
      "metadata": {
        "id": "HZ0r-M2a572c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise Exploratória\n",
        "Tentar visualizar os dados do email"
      ],
      "metadata": {
        "id": "B_53DkAxL-yO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pré-processamento\n",
        "* Utilizaremos regex para tirar links do texto do email e conver ter para minúscula\n",
        "* Utilizaremos um modelo de linguagem da spacy para fazer limpezas, tratamentos e anotacões no texto de cada email\n",
        "* Chamar nlp(txt) processa o texto de entrada txt usando o pipeline do spaCy carregado. Tokeniza o texto, realiza anotações linguísticas (exceto NER e parsing, que foram desativados) e retorna um objeto Doc contendo esta informação processada. Este objeto Doc pode então ser usado para extrair as features desejadas, como lemas para modelagem de tópicos."
      ],
      "metadata": {
        "id": "1icQjtVWHh3N"
      }
    }
  ]
}