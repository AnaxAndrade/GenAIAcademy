{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercício: Descoberta de Tópicos em E-mails Corporativos\n",
        "* **Descrição:** Extraia 5 temas dominantes nos e-mails da Enron para obter visão geral dos assuntos tratados internamente.\n",
        "* **Dataset:** Enron Email Dataset (500 k mensagens de email de uma empresa real, que foi publicada enquanto a empresa estava sendo investigada)\n",
        "  * **Mais Informações:** https://www.cs.cmu.edu/~enron/\n",
        "  * **Download:** https://www.kaggle.com/datasets/wcukierski/enron-email-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Passo a passo\n",
        "1. Descarregar emails.csv (colunas message, subject, date, user).\n",
        "2. Filtrar apenas “sent” e “inbox”; amostrar 20 000 linhas para caber em RAM de portátil.\n",
        "3. Pré-processar: minúsculas, remover URLs, stop-words, lematizar (spacy-pt).\n",
        "4. CountVectorizer → matriz BoW (max_features=20 000).\n",
        "5. LatentDirichletAllocation(n_components=5, max_iter=10); ajustar modelo.\n",
        "6. Mostrar top-10 palavras de cada tópico e atribuir rótulos de negócio.\n",
        "7. Calcular distribuição de tópicos por utilizador e visualizar em gráfico de barras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgGl2wm69x0o"
      },
      "source": [
        "## Download do Dataset\n",
        "* Para facilitar, fiz o upload do arquivo .csv no Google drive, link: https://drive.google.com/file/d/1FiIb0dliKf18NsbSCZmz27xXy0MXV8Iq/view\n",
        "* Para fazer download é só executar o comando mais abaixo\n",
        "* Caso o link ou o comando abaixo não funcionem, tem de fazer o download direto do próprio kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQtjRBYS-Nj4"
      },
      "outputs": [],
      "source": [
        "# Opcional: Se quizer fazer o download do arquivo direto do meu Google Drive\n",
        "\n",
        "# NOTA: Em ambiente do Google colab o gdown já funciona diretamente\n",
        "# caso necessário pode instalá-lo via pip, descomentanto a linha abaixo:\n",
        "# !pip install gdown\n",
        "\n",
        "!gdown 1FiIb0dliKf18NsbSCZmz27xXy0MXV8Iq -O emails.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utyg_sf15yFH"
      },
      "outputs": [],
      "source": [
        "# Dependências\n",
        "#!pip install pandas scikit-learn spacy==3.7.2 spacy-lookups-data pyLDAvis\n",
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouH9xetb53Ud"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, re, spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ0r-M2a572c"
      },
      "outputs": [],
      "source": [
        "# 1. carregar\n",
        "# NOTA: O dataset completo inclui mais de 500 mil emails\n",
        "# Para uma análise inicial pode ser interessante carregar uma amostra menor\n",
        "# por questões de tempo e performance\n",
        "amostra = 20000\n",
        "\n",
        "df = pd.read_csv('emails.csv')\n",
        "df = df[df['file'].str.contains('sent|inbox', na=False)].sample(amostra, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_53DkAxL-yO"
      },
      "source": [
        "# Análise Exploratória\n",
        "Tentar visualizar os dados do email"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1icQjtVWHh3N"
      },
      "source": [
        "## Pré-processamento\n",
        "* Utilizaremos regex para tirar links do texto do email e conver ter para minúscula\n",
        "* Utilizaremos um modelo de linguagem da spacy para fazer limpezas, tratamentos e anotacões no texto de cada email\n",
        "* Chamar nlp(txt) processa o texto de entrada txt usando o pipeline do spaCy carregado. Tokeniza o texto, realiza anotações linguísticas (exceto NER e parsing, que foram desativados) e retorna um objeto Doc contendo esta informação processada. Este objeto Doc pode então ser usado para extrair as features desejadas, como lemas para modelagem de tópicos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
